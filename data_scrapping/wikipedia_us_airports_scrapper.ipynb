{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">A notebook that extracts US airport tables by state from Wikipedia and saves them as CSV files. This can be useful for categorizing airports (e.g., civil, military, other; global, local, regional, etc.).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Warning:</b> The airport category (APT_CAT) still needs to be mapped to standardized codes. For example, 'Other military/government airports' and 'Other government/military airports' refer to the same category but are written differently depending on the Wikipedia page. These variations should be harmonized to ensure consistency. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "from io import StringIO\n",
    "from polars import col as d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## states list\n",
    "states = [\n",
    "    \"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\n",
    "    \"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\n",
    "    \"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\n",
    "    \"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New_Hampshire\",\"New_Jersey\",\"New_Mexico\",\n",
    "    \"New_York\",\"North_Carolina\",\"North_Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "    \"Rhode_Island\",\"South_Carolina\",\"South_Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\n",
    "    \"Virginia\",\"Washington\",\"West_Virginia\",\"Wisconsin\",\"Wyoming\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports = [] ## empty list to save the tables and concat them after\n",
    "\n",
    "## loop for all states\n",
    "for state in states:\n",
    "\n",
    "    ## handle special Wikipedia page URLs for certain states\n",
    "    if state == \"Washington\":\n",
    "        url = f\"https://en.wikipedia.org/wiki/List_of_airports_in_Washington_(state)\"\n",
    "    elif state == \"New_York\":\n",
    "        url = f\"https://en.wikipedia.org/wiki/List_of_airports_in_New_York_(state)\"\n",
    "    elif state == \"Georgia\":\n",
    "        url = f\"https://en.wikipedia.org/wiki/List_of_airports_in_Georgia_(U.S._state)\"\n",
    "\n",
    "    ## default URL format for other states\n",
    "    else:\n",
    "        url = f\"https://en.wikipedia.org/wiki/List_of_airports_in_{quote(state)}\"\n",
    "\n",
    "    ## set a User-Agent to avoid request blocking\n",
    "    ## basically we pretend to be a browser to be able to access the data\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    try:\n",
    "        ## send HTTP GET request to Wikipedia\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status() ## raise an error if request fails\n",
    "\n",
    "        html_data = StringIO(response.text) ## convert HTML content to a file-like object\n",
    "        tables = pd.read_html(html_data) ## read all HTML tables on the page with pandas\n",
    "\n",
    "        ## filter tables to keep only those that have columns \"Airport name\" or \"Role\"\n",
    "        ## this helps avoid parsing unwanted tables like banners or notices\n",
    "        tables = [t for t in tables if 'Airport name' in t.columns or 'Role' in t.columns]\n",
    "\n",
    "        if not tables:\n",
    "            print(f\"No airport table found for {state}\")\n",
    "            continue ## skip this state if no valid table is found\n",
    "\n",
    "        df = tables[0] ## take the first valid table\n",
    "        df[\"STATE\"] = state ## add a columns with the state name\n",
    "\n",
    "\n",
    "        df['APT_CAT'] = pd.Series(dtype=\"object\") ## create a new columns for aiport category\n",
    "        airport_col = df.columns[4] ## the 5th columns (zero-indexed) contains the airport name and category (weird structure from Wikip√©dia)\n",
    "        other_cols = [c for c in df.columns if c not in ['STATE', airport_col]] ## the others columns\n",
    "        current_category = None\n",
    "\n",
    "        ## loop over rows to assign airport category\n",
    "        for idx, row in df.iterrows():\n",
    "            ## detect rows that are only category headers:\n",
    "            ## 'airport_col' is not NaN, all other columns (except STATE) are NaN            \n",
    "            if pd.notna(row[airport_col]) and row[other_cols].isna().all():\n",
    "                current_category = row[airport_col]\n",
    "                df.at[idx, 'APT_CAT'] = current_category ## update current category\n",
    "            else:\n",
    "                df.at[idx, 'APT_CAT'] = current_category ## assign category to regular rows\n",
    "\n",
    "        ## remove rows where the first column is NaN (often empty or banner rows)\n",
    "        df = df[df[df.columns[0]].notna()].reset_index(drop=True)\n",
    "\n",
    "        ## Hawaii has a different column name for the city, handle separately\n",
    "        if state == 'Hawaii':\n",
    "            df_pl = (pl.from_pandas(df) ## convert Pandas DataFrame to Polars\n",
    "                    .rename({'City served, Island':'CITY_SERVED', 'Airport name':'APT_NAME', 'Role':'FAA_ROLE', 'IATA':'IATA_CODE', 'ICAO':'ICAO_CODE'})\n",
    "                    .select(['IATA_CODE', 'ICAO_CODE', 'APT_NAME', 'APT_CAT', 'FAA_ROLE', 'STATE', 'CITY_SERVED']) ## process naming & keep certain columns\n",
    "            )\n",
    "        else:\n",
    "            df_pl = (pl.from_pandas(df)\n",
    "                    .rename({'City served':'CITY_SERVED', 'Airport name':'APT_NAME', 'Role':'FAA_ROLE', 'IATA':'IATA_CODE', 'ICAO':'ICAO_CODE'})\n",
    "                    .select(['IATA_CODE', 'ICAO_CODE', 'APT_NAME', 'APT_CAT', 'FAA_ROLE', 'STATE', 'CITY_SERVED'])\n",
    "            )\n",
    "\n",
    "        all_airports.append(df_pl) ## add processed Polars DataFrame to the list\n",
    "        print(f\"{state} : {len(df)} added lines\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {state} : {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports_df = pl.concat(all_airports) ## concat everything\n",
    "all_airports_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_airports_df.write_csv(\"airports_us_wikipedia.csv\")\n",
    "# print(\"CSV saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports_df['APT_CAT'].unique().to_list() ## do a mapping to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
